{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3dc0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69536be",
   "metadata": {},
   "source": [
    "## FSPOOL: a differentiable, sorting-based pooling method for variable-size sets\n",
    "\n",
    "We are given a set of n feature vectors X = [x(1), . . . , x(n)] where each x(i) is a column vector of\n",
    "dimension d placed in some arbitrary order in the columns of X ∈ Rd×n. From this, the goal is to\n",
    "produce a single feature vector in a way that is invariant to permutation of the columns in the matrix.\n",
    "We first sort each of the d features across the elements of the set by numerically sorting within the\n",
    "rows of X to obtain the matrix of sorted features ~X:\n",
    "~Xi,j = SORT(Xi,:)j (3)\n",
    "where Xi,: is the ith row of X and SORT(·) sorts a vector in descending order. \n",
    "\n",
    "hile this may appear\n",
    "strange since the columns of ~X no longer correspond to individual elements of the set, there are good\n",
    "reasons for this. A transformation (such as with an MLP) prior to the pooling can ensure that the\n",
    "features being sorted are mostly independent so that little information is lost by treating the features\n",
    "independently. Also, if we were to sort whole elements by one feature, there would be discontinuities\n",
    "whenever two elements swap order\n",
    "\n",
    "Then, we apply a learnable weight matrix W ∈ Rd×n to ~X by elementwise multiplying and summing\n",
    "over the columns (row-wise dot products).\n",
    "yi =\n",
    "n∑\n",
    "j\n",
    "Wi,j ~Xi,j (4)\n",
    "y ∈ Rd is the final pooled representation of ~X. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32c3e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "class FSPool(nn.Module):\n",
    "    def __init__(self, in_channels, n_pieces, relaxed=False):\n",
    "        super().__init__()\n",
    "        self.n_pieces = n_pieces\n",
    "        self.weight = nn.Parameter(torch.zeros(in_channels, n_pieces+1))\n",
    "        self.relaxed = relaxed\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.weight)\n",
    "\n",
    "    def forward(self, x, n=None):#FSPool\n",
    "        assert x.size(1) == self.weight.size(0), \"incorrect number of input channels in weight\"\n",
    "\n",
    "        if n is None:\n",
    "            n = torch.full((x.size(0),),x.size(2), dtype=torch.long, device=x.device)\n",
    "\n",
    "        sizes, mask = fill_sizes(n, x)\n",
    "        mask = mask.expand_as(x)\n",
    "\n",
    "        weight = self.determine_weight(sizes)\n",
    "\n",
    "        x = x + (1-mask).float() * -99999\n",
    "\n",
    "        if self.relaxed:\n",
    "            x, perm = cont_sort(x, temp=self.relaxed)\n",
    "        else:\n",
    "            x, perm = x.sort(dim=2, descending=True)\n",
    "\n",
    "        x = (x*weight*mask.float()).sum(dim=2)\n",
    "\n",
    "        return x, perm\n",
    "    \n",
    "    def forward_transpose(self, x, perm, n=None):#FSUnpool\n",
    "        if n is None:\n",
    "            n = x.new(x.size(0)).fill_(perm.size(2)).long()\n",
    "\n",
    "        sizes, mask = fill_sizes(n)\n",
    "        mask = mask.expand(mask.size(0), x.size(1), mask.size(2))\n",
    "\n",
    "        weight = self.determine_weight(sizes)\n",
    "\n",
    "        x = x.unsqueeze(2) * weight * mask.float()\n",
    "\n",
    "        if self.relaxed:\n",
    "            x, _ = cont_sort(x, perm)\n",
    "        else:\n",
    "            x = x.scatter(2, perm, x)\n",
    "\n",
    "        return x, mask\n",
    "    \n",
    "    def determine_weight(self, sizes):\n",
    "        \"\"\"\n",
    "        Piecewise Linear Function. Evaluates f at ratios in sizes.\n",
    "        faster as we know most terms are 0\n",
    "        \n",
    "        \"\"\"\n",
    "        weight = self.weight.unsqueeze(0)\n",
    "        weight = weight.expand(sizes.size(0), weight.size(1), weight.size(2))\n",
    "\n",
    "        index = self.n_pieces * sizes\n",
    "        index = index.unsqueeze(1)\n",
    "        index = index.expand(index.size(0), weight.size(1), index.size(2))\n",
    "\n",
    "        idx = index.long()\n",
    "        frac = index.frac()\n",
    "        left = weight.gather(2, idx)\n",
    "        right = weight.gather(2, (idx+1).clamp(max=self.n_pieces))\n",
    "\n",
    "        return (1-frac)*left + frac*right\n",
    "    \n",
    "\n",
    "\n",
    "def fill_sizes(sizes, x=None):\n",
    "    \"\"\"\n",
    "    Each set size n is turned to [0/(n-1), 1/(n-1), .... ,1, 0, 0, ... ,0]\n",
    "    \"\"\"\n",
    "\n",
    "    if x is not None:\n",
    "        max_size = x.size(2)\n",
    "    else:\n",
    "        max_size = sizes.max()\n",
    "\n",
    "    size_tensor = sizes.new(sizes.size(0), max_size).float().fill_(-1)\n",
    "\n",
    "    size_tensor = torch.arange(end=max_size, device=sizes.device, dtype=torch.float32)\n",
    "    size_tensor = size_tensor.unsqueeze(0) / (sizes.float()-1).clamp(min=1).unsqueeze(1)\n",
    "\n",
    "    mask = size_tensor<=1\n",
    "    mask = mask.unsqueeze(1)\n",
    "\n",
    "    return size_tensor.clamp(max=1), mask.float()\n",
    "\n",
    "def deterministic_sort(s, tau):\n",
    "\n",
    "    \"\"\"\n",
    "    s:input elements to be sorted shape: b x n x 1\n",
    "    tau: temperature for relaxation: scalar\n",
    "    \"\"\"\n",
    "\n",
    "    n = s.size()[1]\n",
    "\n",
    "    one = torch.ones((n,1), dtype=torch.float32, device=s.device)\n",
    "    A_s = torch.abs(s - s.permute(0, 2, 1))\n",
    "    B = torch.matmul(A_s, torch.matmul(one, one.transpose(0 , 1)))\n",
    "    scaling = (n + 1 - 2 * (torch.arange(n, device=s.device) + 1)).type(torch.float32)\n",
    "    C = torch.matmul(s, scaling.unsqueeze(0))\n",
    "    P_max = (C-B).permute(0, 2, 1)\n",
    "    sm = torch.nn.Softmax(-1)\n",
    "    P_hat = sm(P_max / tau)\n",
    "    return P_hat\n",
    "\n",
    "def cont_sort(x, perm=None, temp=1):\n",
    "    original_size = x.size()\n",
    "\n",
    "    x = x.view(-1, x.size(2), 1)\n",
    "\n",
    "    if perm is None:\n",
    "        perm = deterministic_sort(x, temp)\n",
    "    else:\n",
    "        perm = perm.transpose(1,2)\n",
    "\n",
    "    x = perm.matmul(x)\n",
    "    x = x.view(original_size)\n",
    "    return x, perm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f40e0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELementEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes each instance into a latent embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): #(B, N, D)\n",
    "        return self.net(x) #(B, N, H)\n",
    "    \n",
    "class SetEncoder(nn.Module):\n",
    "    \"\"\"\"\n",
    "    Encodes complete set into permutation invariant vector using FSPool\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, n_pieces=4):\n",
    "        super().__init__()\n",
    "        self.pool = FSPool(in_channels=hidden_dim, n_pieces=n_pieces)\n",
    "        self.out = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pooled, _ = self.pool(x.transpose(1, 2)) #(B, H)\n",
    "        return self.out(pooled)\n",
    "    \n",
    "class SetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Predicts an output set (or refined set)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, pred_set, set_embed):\n",
    "        set_embed = set_embed.unsqueeze(1).expand_as(pred_set)\n",
    "        return pred_set + self.net(torch.cat([pred_set, set_embed], dim=-1))\n",
    "    \n",
    "\n",
    "class DSPN_FSPool(nn.Module):\n",
    "    \"\"\"\n",
    "    Full DSPN Pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim, set_size, num_classes, n_pieces=4, num_iters=5):\n",
    "        super().__init__()\n",
    "        self.encoder = ELementEncoder(in_dim, hidden_dim)\n",
    "        self.set_encoder = SetEncoder(hidden_dim, n_pieces)\n",
    "        self.decoder = SetDecoder(hidden_dim)\n",
    "        self.num_iters = num_iters\n",
    "        self.set_size = set_size\n",
    "\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_set):\n",
    "        \"\"\"\n",
    "        input_set: (B, N, D)\n",
    "        return: class logits, predicted set\n",
    "        \"\"\"\n",
    "\n",
    "        B, N, D = input_set.shape\n",
    "\n",
    "        encoded = self.encoder(input_set) #(B, N, H)\n",
    "\n",
    "        pred_set = torch.zeros(B, self.set_size, encoded.size(-1), device=input_set.device)\n",
    "        target_embed = self.set_encoder(encoded) #(B, H)\n",
    "\n",
    "        for _ in range(self.num_iters):\n",
    "            pred_embed = self.set_encoder(pred_set)\n",
    "            pred_set = self.decoder(pred_set, target_embed-pred_embed)\n",
    "\n",
    "        final_embed = self.set_encoder(pred_set)\n",
    "        logits = self.classifier(final_embed)\n",
    "\n",
    "        return logits, pred_set\n",
    "    \n",
    "    def compute_loss(self, input_set, labels):\n",
    "        logits, pred_set = self.forward(input_set)\n",
    "        cls_loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        encoded = self.encoder(input_set)\n",
    "        target_embed = self.set_encoder(encoded)\n",
    "        pred_embed = self.set_encoder(pred_set)\n",
    "        recon_loss = F.mse_loss(pred_embed, target_embed)\n",
    "\n",
    "        return cls_loss + 0.1 * recon_loss, cls_loss, recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3dd98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1269994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_patches(x, patch_size=4):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.unfold(2, patch_size, patch_size).unfold(3, patch_size, patch_size)\n",
    "    x = x.contiguous().view(B, C, -1, patch_size, patch_size) #(B, 1, N, p, p)\n",
    "    x = x.permute(0, 2, 1, 3, 4) #(B, N, C, p, p)\n",
    "    x = x.reshape(B, x.size(1), -1) #(B, N, p)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2f815bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 4\n",
    "set_size = (28 // patch_size) ** 2  # 49\n",
    "patch_dim = patch_size * patch_size  # 16\n",
    "hidden_dim = 128\n",
    "num_classes = 10\n",
    "\n",
    "model = DSPN_FSPool(in_dim=patch_dim, hidden_dim=hidden_dim, set_size=set_size,\n",
    "                    num_classes=num_classes, n_pieces=8, num_iters=5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f66407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=0.4895, acc=0.8663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.4695, acc=0.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=0.4638, acc=0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss=0.4437, acc=0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss=0.4366, acc=0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss=0.4227, acc=0.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: loss=0.4195, acc=0.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: loss=0.4089, acc=0.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: loss=0.4062, acc=0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: loss=0.3902, acc=0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss=0.3932, acc=0.8964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: loss=0.3823, acc=0.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: loss=0.3800, acc=0.9027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: loss=0.3844, acc=0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: loss=0.3689, acc=0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: loss=0.3675, acc=0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: loss=0.3623, acc=0.9071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: loss=0.3652, acc=0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: loss=0.3463, acc=0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: loss=0.3472, acc=0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: loss=0.3522, acc=0.9114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: loss=0.3414, acc=0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: loss=0.3320, acc=0.9150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: loss=0.3341, acc=0.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: loss=0.3311, acc=0.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(f'using device: {device}')\n",
    "\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}\", leave = False)\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Convert images to patch sets\n",
    "        x = image_to_patches(images, patch_size=patch_size)\n",
    "\n",
    "        loss, cls_loss, recon_loss = model.compute_loss(x, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        preds = model.forward(x)[0].argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samples += images.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch}: loss={total_loss/total_samples:.4f}, acc={total_correct/total_samples:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
